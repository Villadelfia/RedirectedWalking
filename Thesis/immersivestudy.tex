\section{Opstelling}
Om een vloeiende werking te verzekeren werd de virtuele omgeving gedraaid op een
Apple MacBook Pro met een 2,5 GHz Intel Core i5 processor, 8 GB 1333 MHz DDR3 RAM
geheugen en een Intel HD Graphics 4000 GPU. Het beeld werd getoond op een Oculus 
Rift (Devkit 1) aan 60 fps voor beide ogen. Deze HMD heeft een diagonale FoV van 
110\textdegree{} en vult hierdoor bijna het hele zicht van de proefpersonen voor 
een maximale immersie.

Tracking van positie en rotatie in 3 assen werd gedaan door een 6 camera
OptiTrack systeem rondom een 3 m x 4 m omgeving. Om gebruikersinvoer te voorzien 
heb ik gewoon een bluetooth muis gebruikt, zodat de proefpersoon op eender welke 
knop kon klikken om het object voor hem te activeren.

\section{Beschrijving}
Elke testpersoon kreeg een 
briefing waar hem verteld werd dat hij door een virtueel kantoor zou gaan
wandelen. Ik deelde hem mee dat hij in elk kantoor de blinden zou moeten sluiten 
met de knop naast het raam, en dat hij de foto boven deze knop moest onthouden.
Vervolgens werd hem gevraagd het kantoor te verlaten en de deur achter hem te
sluiten en dit proces voor 3 kantoren te herhalen. Er werd ook kort aan de 
proefpersonen verteld hoe ze moesten interageren met de virtuele omgeving.

Vervolgens werd er gevraagd of er onduidelijkheden waren en begaven we ons naar 
de startpositie, en werd de proefpersoon de Oculus Rift aangeboden om zelf op te 
zetten. Na de uitvoering van het experiment werd de proefpersoon een korte 
vragenlijst voorgelegd.


\section{Vragenlijst}
De vragenlijst bestond uit een informatieblok en vijf vragen. Ze was beschikbaar
in het Nederlands en het Engels. De Nederlandse versie van de vragenlijst is
ingevoegd in Bijlage \ref{vragenlijst}. In het informatieblok wordt er gevraagd 
naar de leeftijd en het geslacht van de proefpersoon, dit om potentieel te 
analyseren of er verschillen in effectiviteit tussen deze groepen zijn.

Vervolgens wordt er gevraagd om een schema van het grondplan te tekenen, om te
zien of er ondanks de onmogelijke ruimte toch een consistent mentaal beeld kon
gevormd worden. Daarna wordt er gevraagd om de drie fotos op te noemen, deze
vraag is niet verwerkt in de resultaten daar deze een onderdeel uitmaakt van de
afleiders. In vraag drie moet de proefpersoon aan acht stellingen een score 
toekennen van 1 tot 6 waar 1 betekent dat hij het niet heeft gemerkt, en 6 dat 
het heel duidelijk wel is gebeurd:

\begin{enumerate}
  \item Ik zag de virtuele omgeving groter of kleiner worden.
  \item \emph{Ik voelde alsof ik het zelfde pad aan het belopen was.}
  \item Ik zag de virtuele omgeving flitsen.
  \item \emph{Ik merkte dat iets in de omgeving zich van plaats had veranderd.}
  \item Ik zag de virtuele omgeving roteren.
  \item Ik voelde mezelf groter of kleiner worden.
  \item Ik voelde me alsof ik bewogen werd.
  \item Ik merkte dat iets in de virtuele omgeving groter of kleiner werd.
\end{enumerate}

Enkel de schuingedrukte stellingen zijn echt gebeurd, de andere stellingen zouden
een zeer lage gemiddelde score moeten hebben. De laatste twee vragen bestaan uit 
een vraag waar wordt gevraagd voor algemene qualitatieve feedback over de 
immersie, en een vraag waar wordt gevraagd om de bewogen voorwerpen te 
identificeren.

De vragenlijst is gebaseerd op de vragenlijst uit het eerdere experiment van Evan
A. Suma\cite{suma11}.


\section{Uitvoering}
Het experiment is uitgevoerd met 17 proefpersonen, 4 vrouwen en 13 mannen.
Leeftijden varieerden van 21 tot 47 jaar oud met een gemiddelde van 30. Slechts
3 personen hadden geen spelervaring. Omdat zowel de groep van vrouwen als de
groep van mensen zonder spelervaring te klein is kunnen deze groepen helaas
niet apart bekeken worden. Maar op het eerste zicht lijkt er geen significant
verschil te zijn in de resultaten van deze groepen.


\section{Implementatie}
\subsection{Engine}
Voor de implementatie van de virtuele omgeving heb ik er voor gekozen om met de
Unity engine te werken. Ik heb deze keuze gemaakt omdat de Unity engine relatief
eenvoudig is om mee te werken en mij meer tijd over laat om te werken aan de
benodigde algoritmen. Voor het ontwerp van de omgeving heb ik gebruik gemaakt 
van de Blender 3D editor, wegens eerdere ervaring met deze editor.

Ik beschrijf nu even kort de belangrijke details van mijn implementatie.


\subsubsection{Systeem state}
Voor de state van het systeem maak ik gebruik van stappen, er is op elk moment
slechts een object dat reageert op interactie. Wegens de volledig lineaire aard
van het systeem, en de relatief kleine hoeveelheid stappen is dit op de meest 
voor de hand liggende methode opgelost: Met een switch statement die de correcte
animaties dispatcht. Met wat onnodige details weggelaten ziet dit er zo uit:

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{csharp}
// ...
private int _ctr = 1;
// ...

void Update() {
    // Decrement the delay between actions
    _timeout -= Time.deltaTime;

    // Check if a transition is requested, 
    // and that it is allowed by position, view and timeout
    if((Input.GetButtonDown("Activate")) && 
            _timeout <= 0f && 
            CanTriggerNextStep()) {
        // Reset the timeout
        _timeout = 1.5f;

        // Make the animation happen based on the active step
        switch(_ctr) {
        case 1: // Clicking button in room 1
            StartCoroutine(MoveHallway(0f, 0f, 1.6f));
            StartCoroutine(DescendBlinds());
            StartCoroutine(DepressButton());
            break;
        case 2: // Closing door of room 1
            StartCoroutine(RotateDoor(Door1));
            StartCoroutine(RespawnRoom(0.6f));
            StartCoroutine(RotateDoor(Door2, 0.6f, false));
            break;
        case 3: // Clicking button in room 2
            StartCoroutine(MoveHallway(0f, 0f, 1.6f));
            StartCoroutine(DescendBlinds());
            StartCoroutine(DepressButton());
            break;
        case 4: // Closing door of room 2
            StartCoroutine(RotateDoor(Door2));
            StartCoroutine(RespawnRoom(0.6f));
            StartCoroutine(RotateDoor(Door3, 0.6f, false));
            break;
        case 5: // Clicking button in room 3
            StartCoroutine(MoveHallway(0f, 0f, 1.6f));
            StartCoroutine(DescendBlinds());
            StartCoroutine(DepressButton());
            break;
        case 6: // Closing door of room 3
            StartCoroutine(RotateDoor(Door3));
            StartCoroutine(RespawnRoom(0.6f, 0f, -1f, 0f, -1.6f));
            StartCoroutine(RotateDoor(Door4, 0.6f, false));
            break;
        }

        // Increment the "step" of the process
        ++_ctr;
    }
}
\end{minted}


\subsubsection{Interactie}
Bij de activatie van deuren en knoppen wordt er eerst gekeken of de proefpersoon
zich op minder dan een meter afstand van het object bevind, en of hij het object
in beeld heeft. Als aan beide voorwaarden wordt voldaan wordt de animatie
geactiveerd.

Voor beide delen van deze check maak ik gebruik van de ingebouwde functionaliteit
van Unity. Lichtjes ingekort, ziet de code er zo uit:

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{csharp}
bool CanTriggerNextStep(Transform object) {
    return InView(object) && Distance(object) <= 1f;
}

// Returns the distance on the XZ plane of our position to a point
float Distance(Vector3 pos) {
    Vector2 v1 = new Vector2(tracker.GetX(), tracker.GetY());
    Vector2 v2 = new Vector2(pos.x, pos.z);
    Debug.Log(Vector2.Distance(v1, v2));
    return Vector2.Distance(v1, v2);
}

// Is Vector3 in view
bool InView(Vector3 v) {
    v.y = Camera.main.transform.position.y;
    Vector3 vis = Camera.main.WorldToViewportPoint(v);
    if((vis.x < 0 || vis.x > 1) || vis.z <= 0) {
        return false;
    }
    return true;
}
\end{minted}


\subsubsection{Animatie}
Voor de animaties maak ik gebruik van sferische lineaire interpolatie tussen de
begin- en de eindpositie van de te animeren objecten.

Sferische lineaire interpolatie wordt standaard door Unity meegeleverd. Volgende
stukjes code tonen de implementatie van respectievelijk het laten dalen van de
blinden, het indrukken van de knoppen, en het sluiten van de deuren.

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{csharp}
// Play the animation for closing the blinds
IEnumerator DescendBlinds(float delay = 0f) {
    yield return new WaitForSeconds(delay);
    Vector3 begin = _blinds.transform.position;
    Vector3 end = begin - new Vector3(0f, 0.995f, 0f);

    for(float i = 0f; i < 1.5f; i += Time.deltaTime) {
        _blinds.transform.position = Vector3.Slerp(begin, end, 
                i / 1.5f);
        yield return true;
    }

    _blinds.transform.position = end;
    yield return true;
}

// Play the animation for pressing the button
IEnumerator DepressButton(float delay = 0f, 
        bool isRotated = false) {
    yield return new WaitForSeconds(delay);
    Vector3 begin = _button.transform.position;
    Vector3 end = begin + (isRotated ? new Vector3(0.03f, 0f, 0f) : 
            new Vector3(0f, 0f, -0.03f));

    for(float i = 0f; i < 0.25f; i += Time.deltaTime) {
        _button.transform.position = Vector3.Slerp(begin, end, 
                i / 0.25f);
        yield return true;
    }

    _button.transform.position = end;
    yield return true;
}

// Open or close a door, meaning a 90 degree rotation in a 
// certain direction
IEnumerator RotateDoor(GameObject door, float delay = 0f, 
        bool close = true) {
    yield return new WaitForSeconds(delay);

    float angle = door.transform.rotation.eulerAngles.y;
    float goal = close ? angle - 90 : angle + 90;
    Quaternion end = Quaternion.AngleAxis(goal, Vector3.up);
    Quaternion begin = door.transform.rotation;

    for(float i = 0f; i < 0.5f; i += Time.deltaTime) {
        door.transform.rotation = Quaternion.Slerp(begin, end, 
                i / 0.5f);
        yield return true;
    }

    door.transform.rotation = end;
    yield return true;
}
\end{minted}

Voor de ``animatie'' van de beweging van de gang wordt er helemaal geen animatie
gedaan, omdat deze niet in het zicht van de proefpersoon is. Daar de deuren in
het object van de gang verwerkt zitten, is deze beweging de effectieve
implementatie van change blindness in deze virtuele omgeving.

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{csharp}
// Move the hallway 1.6m back.
IEnumerator MoveHallway(float x, float y, float z, 
        float delay = 0) {
    yield return new WaitForSeconds(delay);
    Hallway.transform.Translate(x, y, z);
    yield return true;
}
\end{minted}

\subsection{Tracking}
Voor integratie met het trackingsysteem heb ik gebruik gemaakt van de gratis
editie van de MiddleVR middleware\cite{middlevr}. Deze maakt het mogelijk om via 
het VRPN protocol te communiceren met de tracking server.

MiddleVR geeft ook toegang tot ``virtual trackers'' waarmee men de data van een
tracker kan transformeren. Het resultaat hiervan is dat ik de pitch en de roll
van de HMD heb kunnen gebruiken, en de yaw van het camera tracking systeem. Dit
omdat de HMD een kleine hoeveelheid ``yaw drift'' heeft, en dit zou kunnen zorgen
voor botsingen met de fysieke omgeving.

Ik heb dit systeem ook gebruikt om de trillingen in de gerapporteerde yaw van het
trackingsysteem te verminderen door een gemiddelde van twee metingen te 
gebruiken. Daar de \emph{framerate} van het systeem voldoende is, heeft dit bijna 
geen effect op de latency van de bewegingen (effectief een latency van 16 ms bij
een framerate van 60 Hz). In de praktijk werkt dit door te werken met het 
gemiddelde van de vorige meting en de nieuwe meting in plaats van met de rauwe 
meting.

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{csharp}
private float getModifiedYaw() {
    // Get yaw from optitrack tracker.
    float a = optiTrack.GetYaw() - yawZeroOpti;
    a = normAngle(a);

    // If not first frame, take avg of last 2 measurements.
    if(!firstFrame) {
        if(Mathf.Abs(a - prevYaw) > 180.0f) {
            if(a > prevYaw) {
                prevYaw += 360.0f;
            } else {
                a += 360.0f;
            }
        }
        a = (a + prevYaw) / 2.0f;
    }
    a = normAngle(a);
    prevYaw = a;

    return a - 180.0f;
}

private float normAngle(float a) {
    while(a < 0) {
        a += 360;
    }

    while(a >= 360) {
        a -= 360;
    }

    return a;
}
\end{minted}

Ik heb hier uitdrukkelijk geen gebruik gemaakt van een Kalman filter wegens de
precisie van het OptiTrack systeem tot op minder dan een millimeter. Hierdoor
is mijn techniek ruim voldoende om de zeer kleine hoeveelheid jitter op te
vangen.

Aan de serverkant heb ik gebruik gemaakt van de OptiTrack:Motive software om de
VRPN data te broadcasten.
